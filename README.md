# ML-проект: Автоматическая категоризация товаров по изображениям

## Цель проекта

**Бизнес-цель:** Разработка системы автоматической категоризации товаров в интернет-магазине на основе изображений для ускорения процесса добавления новых товаров в каталог и улучшения пользовательского опыта поиска. Система позволит автоматически определять категорию товара по его изображению, что сократит время на ручную категоризацию и уменьшит количество ошибок.

**Техническая цель:** Создать модель глубокого обучения, способную классифицировать изображения товаров по категориям с высокой точностью, и развернуть её в продакшене с соблюдением требований по производительности и надежности.

## Набор данных

Для обучения модели будет использован датасет **Fashion-MNIST** или расширенный датасет с изображениями товаров различных категорий.

### Характеристики датасета:
- **Тип данных:** Изображения товаров (одежда, обувь, аксессуары и т.д.)
- **Размер:** ~70,000 изображений для обучения, ~10,000 для валидации
- **Формат:** Градации серого изображения размером 28x28 пикселей
- **Классы:** 10 категорий товаров:
  - T-shirt/top (Футболка)
  - Trouser (Брюки)
  - Pullover (Свитер)
  - Dress (Платье)
  - Coat (Пальто)
  - Sandal (Сандалии)
  - Shirt (Рубашка)
  - Sneaker (Кроссовки)
  - Bag (Сумка)
  - Ankle boot (Ботинки)

Датасет будет загружаться автоматически при первом запуске через PyTorch или может быть предоставлен в виде архивного файла.

## План экспериментов

### Этап 1: Подготовка данных и базовая модель
- Загрузка и анализ датасета Fashion-MNIST
- Предобработка данных (нормализация, аугментация)
- Создание базовой CNN модели
- Обучение на небольшой выборке для проверки pipeline
- Базовая валидация и проверка работоспособности

**Ожидаемый результат:** Рабочий pipeline обучения с базовой моделью, дающей accuracy > 80%

### Этап 2: Оптимизация модели
- Эксперименты с различными архитектурами:
  - Базовая CNN
  - ResNet (адаптированная для Fashion-MNIST)
  - EfficientNet (если возможно масштабирование)
- Подбор гиперпараметров:
  - Learning rate (grid search: 0.0001, 0.001, 0.01)
  - Batch size (32, 64, 128)
  - Optimizer (Adam, SGD, AdamW)
- Применение техник регуляризации:
  - Dropout (0.3, 0.5, 0.7)
  - Batch normalization
  - Data augmentation (random flip, rotation, brightness)
- Анализ метрик качества:
  - Accuracy, Precision, Recall, F1-score
  - Confusion matrix для анализа ошибок

**Ожидаемый результат:** Модель с accuracy ≥ 90% на тестовой выборке

### Этап 3: Оптимизация для продакшена
- Квантизация модели для уменьшения размера (INT8)
- Оптимизация инференса:
  - Конвертация в ONNX формат
  - Оптимизация с помощью TensorRT (если используется GPU)
- Тестирование производительности:
  - Измерение времени инференса
  - Нагрузочное тестирование API
  - Проверка использования памяти и CPU
- Достижение целевых метрик производительности

**Ожидаемый результат:** Модель, удовлетворяющая всем целевым метрикам производительности

### Этап 4: Развертывание и мониторинг
- Создание API сервиса:
  - FastAPI для REST API
  - Обработка изображений (загрузка, предобработка)
  - Обработка ошибок и валидация входных данных
- Контейнеризация:
  - Docker образ с моделью и API
  - Docker Compose для локального развертывания
- Настройка CI/CD pipeline:
  - Автоматические тесты
  - Автоматическое развертывание
- Внедрение логирования и мониторинга:
  - Логирование запросов и ответов
  - Метрики производительности (Prometheus)
  - Алерты при превышении SLA

**Ожидаемый результат:** Полностью развернутый и мониторируемый сервис в продакшене

## Целевые метрики для продакшена

### Метрики производительности сервиса:
- **Среднее время отклика сервиса ≤ 200 мс** (p95 ≤ 300 мс)
  - Включает время загрузки изображения, предобработки, инференса и формирования ответа
- **Доля неуспешных запросов ≤ 1%** (error rate)
  - Учитываются ошибки сервера (5xx), таймауты, ошибки валидации
- **Использование памяти/CPU — в пределах SLA**
  - Память: ≤ 2GB для модели и сервиса
  - CPU: ≤ 70% при пиковой нагрузке (100 запросов/секунду)
- **Пропускная способность:** ≥ 100 запросов/секунду

### Метрики качества модели:
- **Точность (Accuracy) ≥ 90%** на тестовой выборке
- **Precision и Recall ≥ 85%** для каждой категории
- **F1-score ≥ 0.88** (макро-усредненный)

### Дополнительные метрики:
- **Время инференса модели ≤ 50 мс** (на CPU/GPU)
- **Размер модели ≤ 100 MB** (после оптимизации и квантизации)
- **Время холодного старта сервиса ≤ 5 секунд**

## Структура проекта

```
MLOps_Kim/
├── README.md              # Описание проекта
├── requirements.txt       # Зависимости проекта
├── .gitignore            # Игнорируемые файлы
├── data/                 # Данные (не в git)
├── src/                  # Исходный код
│   ├── data/            # Модули для работы с данными
│   ├── models/          # Архитектуры моделей
│   ├── training/        # Скрипты обучения
│   └── inference/       # Код для инференса
├── notebooks/            # Jupyter notebooks для экспериментов
├── tests/               # Тесты
├── configs/             # Конфигурационные файлы
├── docker/              # Docker файлы для развертывания
└── docs/                # Документация
```

## Технологический стек

- **ML Framework:** PyTorch
- **API Framework:** FastAPI
- **Контейнеризация:** Docker
- **Мониторинг:** Prometheus, Grafana (опционально)
- **CI/CD:** GitHub Actions
- **Логирование:** Python logging, структурированные логи

## Установка и запуск

### Установка зависимостей

```bash
pip install -r requirements.txt
```

### Обучение модели

```bash
# Базовый запуск
python src/training/train.py --config configs/config.yaml

# С подробным логированием
python src/training/train.py --config configs/config.yaml --verbose
```

### Параметры скрипта обучения

- `--config` (обязательный): Путь к конфигурационному файлу YAML
- `--verbose`: Включить подробный режим логирования (DEBUG уровень)

### Конфигурация

Основные параметры настраиваются в `configs/config.yaml`:

- **Данные**: путь к данным, batch size, количество воркеров
- **Модель**: архитектура, количество классов, размеры скрытых слоев
- **Обучение**: количество эпох, learning rate, оптимизатор, scheduler
- **Логирование**: директория для логов

### Результаты обучения

После обучения будут созданы:

- `models/best_model/` - лучшая модель (по валидационной точности) в формате Hugging Face
- `models/final_model/` - финальная модель после всех эпох в формате Hugging Face
- `logs/training.log` - лог файл с детальной информацией о процессе обучения

Модели сохраняются в формате Hugging Face (с `config.json` и `pytorch_model.bin`).

## Тестирование

Проект включает комплексное тестирование всех компонентов:

### Запуск тестов

```bash
# Все тесты
pytest tests/ -v

# С покрытием кода
pytest tests/ -v --cov=src --cov-report=html

# Конкретный тест
pytest tests/test_data_validation.py -v
```

### Структура тестов

- `tests/test_data_validation.py` - Тесты валидации данных (формат, типы, признаки, метки)
- `tests/test_prediction_conversion.py` - Тесты конвертации предсказаний модели
- `tests/test_training_pipeline.py` - Тесты pipeline обучения (утилиты, эпохи, воспроизводимость)

### Покрытие тестами

Тесты проверяют:
- Корректность предобработки данных
- Работу pipeline обучения
- Конвертацию предсказаний в финальные значения
- Валидацию данных (формат, типы, диапазоны)
- Воспроизводимость результатов

**Важно:** Тесты проверяют корректность работы pipeline, а не качество модели.

## CI/CD

Проект настроен с автоматическим CI/CD через GitHub Actions:

### Автоматические проверки

При каждом коммите автоматически выполняются:
- Запуск всех тестов на Python 3.9, 3.10, 3.11
- Проверка покрытия кода тестами
- Проверка форматирования кода (black)
- Линтинг кода (flake8)

### GitHub Actions Workflow

Файл `.github/workflows/ci.yml` содержит:
- Job `test`: Запуск тестов на разных версиях Python
- Job `lint`: Проверка форматирования и линтинга

### Локальная проверка

```bash
# Проверка форматирования
black --check src/ tests/

# Форматирование кода
black src/ tests/

# Линтинг
flake8 src/ tests/
```

## Воспроизводимость

Для обеспечения воспроизводимости результатов:

1. Установлен `random_seed` в конфигурации (по умолчанию 42)
2. Все случайные операции используют этот seed
3. Конфигурация сохраняется вместе с моделью
4. Логи содержат все параметры обучения
5. Тесты проверяют воспроизводимость результатов
