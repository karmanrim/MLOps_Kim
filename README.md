# ML-проект: Автоматическая категоризация товаров по изображениям

## Цель проекта

**Бизнес-цель:** Разработка системы автоматической категоризации товаров в интернет-магазине на основе изображений для ускорения процесса добавления новых товаров в каталог и улучшения пользовательского опыта поиска. Система позволит автоматически определять категорию товара по его изображению, что сократит время на ручную категоризацию и уменьшит количество ошибок.

**Техническая цель:** Создать модель глубокого обучения, способную классифицировать изображения товаров по категориям с высокой точностью, и развернуть её в продакшене с соблюдением требований по производительности и надежности.

## Набор данных

Для обучения модели будет использован датасет **Fashion-MNIST** или расширенный датасет с изображениями товаров различных категорий.

### Характеристики датасета:
- **Тип данных:** Изображения товаров (одежда, обувь, аксессуары и т.д.)
- **Размер:** ~70,000 изображений для обучения, ~10,000 для валидации
- **Формат:** Градации серого изображения размером 28x28 пикселей
- **Классы:** 10 категорий товаров:
  - T-shirt/top (Футболка)
  - Trouser (Брюки)
  - Pullover (Свитер)
  - Dress (Платье)
  - Coat (Пальто)
  - Sandal (Сандалии)
  - Shirt (Рубашка)
  - Sneaker (Кроссовки)
  - Bag (Сумка)
  - Ankle boot (Ботинки)

Датасет будет загружаться автоматически при первом запуске через PyTorch или может быть предоставлен в виде архивного файла.

## План экспериментов

### Этап 1: Подготовка данных и базовая модель
- Загрузка и анализ датасета Fashion-MNIST
- Предобработка данных (нормализация, аугментация)
- Создание базовой CNN модели
- Обучение на небольшой выборке для проверки pipeline
- Базовая валидация и проверка работоспособности

**Ожидаемый результат:** Рабочий pipeline обучения с базовой моделью, дающей accuracy > 80%

### Этап 2: Оптимизация модели
- Эксперименты с различными архитектурами:
  - Базовая CNN
  - ResNet (адаптированная для Fashion-MNIST)
  - EfficientNet (если возможно масштабирование)
- Подбор гиперпараметров:
  - Learning rate (grid search: 0.0001, 0.001, 0.01)
  - Batch size (32, 64, 128)
  - Optimizer (Adam, SGD, AdamW)
- Применение техник регуляризации:
  - Dropout (0.3, 0.5, 0.7)
  - Batch normalization
  - Data augmentation (random flip, rotation, brightness)
- Анализ метрик качества:
  - Accuracy, Precision, Recall, F1-score
  - Confusion matrix для анализа ошибок

**Ожидаемый результат:** Модель с accuracy ≥ 90% на тестовой выборке

### Этап 3: Оптимизация для продакшена
- Квантизация модели для уменьшения размера (INT8)
- Оптимизация инференса:
  - Конвертация в ONNX формат
  - Оптимизация с помощью TensorRT (если используется GPU)
- Тестирование производительности:
  - Измерение времени инференса
  - Нагрузочное тестирование API
  - Проверка использования памяти и CPU
- Достижение целевых метрик производительности

**Ожидаемый результат:** Модель, удовлетворяющая всем целевым метрикам производительности

### Этап 4: Развертывание и мониторинг
- Создание API сервиса:
  - FastAPI для REST API
  - Обработка изображений (загрузка, предобработка)
  - Обработка ошибок и валидация входных данных
- Контейнеризация:
  - Docker образ с моделью и API
  - Docker Compose для локального развертывания
- Настройка CI/CD pipeline:
  - Автоматические тесты
  - Автоматическое развертывание
- Внедрение логирования и мониторинга:
  - Логирование запросов и ответов
  - Метрики производительности (Prometheus)
  - Алерты при превышении SLA

**Ожидаемый результат:** Полностью развернутый и мониторируемый сервис в продакшене

## Целевые метрики для продакшена

### Метрики производительности сервиса:
- **Среднее время отклика сервиса ≤ 200 мс** (p95 ≤ 300 мс)
  - Включает время загрузки изображения, предобработки, инференса и формирования ответа
- **Доля неуспешных запросов ≤ 1%** (error rate)
  - Учитываются ошибки сервера (5xx), таймауты, ошибки валидации
- **Использование памяти/CPU — в пределах SLA**
  - Память: ≤ 2GB для модели и сервиса
  - CPU: ≤ 70% при пиковой нагрузке (100 запросов/секунду)
- **Пропускная способность:** ≥ 100 запросов/секунду

### Метрики качества модели:
- **Точность (Accuracy) ≥ 90%** на тестовой выборке
- **Precision и Recall ≥ 85%** для каждой категории
- **F1-score ≥ 0.88** (макро-усредненный)

### Дополнительные метрики:
- **Время инференса модели ≤ 50 мс** (на CPU/GPU)
- **Размер модели ≤ 100 MB** (после оптимизации и квантизации)
- **Время холодного старта сервиса ≤ 5 секунд**

## Структура проекта

```
MLOps_Kim/
├── README.md              # Описание проекта
├── requirements.txt       # Зависимости проекта
├── .gitignore            # Игнорируемые файлы
├── data/                 # Данные (не в git)
├── src/                  # Исходный код
│   ├── data/            # Модули для работы с данными
│   ├── models/          # Архитектуры моделей
│   ├── training/        # Скрипты обучения
│   └── inference/       # Код для инференса
├── notebooks/            # Jupyter notebooks для экспериментов
├── tests/               # Тесты
├── configs/             # Конфигурационные файлы
├── docker/              # Docker файлы для развертывания
└── docs/                # Документация
```

## Технологический стек

- **ML Framework:** PyTorch
- **API Framework:** FastAPI
- **Контейнеризация:** Docker
- **Мониторинг:** Prometheus, Grafana (опционально)
- **CI/CD:** GitHub Actions
- **Логирование:** Python logging, структурированные логи
